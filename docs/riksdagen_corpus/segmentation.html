<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>riksdagen_corpus.segmentation API documentation</title>
<meta name="description" content="Implements the segmentation of the data into speeches and
ultimately into the Parla-Clarin XML format." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>riksdagen_corpus.segmentation</code></h1>
</header>
<section id="section-intro">
<p>Implements the segmentation of the data into speeches and
ultimately into the Parla-Clarin XML format.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Implements the segmentation of the data into speeches and
ultimately into the Parla-Clarin XML format.
&#34;&#34;&#34;
import numpy as np
import pandas as pd
import re, hashlib, copy
import progressbar
from os import listdir
from os.path import isfile, join
from lxml import etree
from riksdagen_corpus.mp import detect_mp
from riksdagen_corpus.download import get_blocks, fetch_files
from riksdagen_corpus.utils import infer_metadata
from riksdagen_corpus.db import filter_db, year_iterator

# Classify paragraph
def classify_paragraph(paragraph, classifier, prior=np.log([0.8, 0.2])):
    &#34;&#34;&#34;
    Classify paragraph into speeches / descriptions with provided classifier

    &#34;&#34;&#34;
    words = paragraph.split()
    V = len(words)
    if V == 0:
        return prior

    x = np.zeros((V, classifier[&#34;dim&#34;]))

    ft = classifier[&#34;ft&#34;]
    for ix, word in enumerate(words):
        vec = ft.get_word_vector(word)
        x[ix] = vec

    pred = classifier[&#34;model&#34;].predict(x, batch_size=V)
    return np.sum(pred, axis=0) + prior

def _is_metadata_block(txt0):
    txt1 = re.sub(&#34;[^a-zA-ZåäöÅÄÖ ]+&#34;, &#34;&#34;, txt0)
    len0 = len(txt0)
    
    # Empty blocks should not be classified as metadata
    if len(txt0.strip()) == 0:
        return False
        
    # Metadata generally don&#39;t introduce other things
    if txt0.strip()[-1] == &#34;:&#34;:
        return False

    # Or list MPs
    if &#34;Anf.&#34; in txt0:
        return False
    
    len1 = len(txt1)
    len2 = len(txt0.strip())
    if len2 == 0:
        return False
    
    # Crude heuristic. Skip if
    # a) over 15% is non alphabetic characters
    # and b) length is under 150 characters
    
    # TODO: replace with ML algorithm
    return float(len1) / float(len0) &lt; 0.85 and len0 &lt; 150

def _detect_mp(matched_txt, names_ids):
    person = None
    for name, identifier in names_ids:
        if name in matched_txt:
            person = identifier
    
    if person == None:
        for name, identifier in names_ids:
            if name.upper() in matched_txt:
                person = identifier
    
    # Only match last name if full name is not found
    if person == None:
        for name, identifier in names_ids:
            last_name = &#34; &#34; + name.split()[-1]
            if last_name in matched_txt:
                person = identifier
            elif last_name.upper() in matched_txt:
                person = identifier
    return person
    
# Instance detection
def find_instances_xml(root, pattern_db, mp_db, classifier):
    &#34;&#34;&#34;
    Find instances of segment start and end patterns in a txt file.

    Args:
        root: root of an lxml tree to be pattern matched.
        pattern_db: Patterns to be matched as a Pandas DataFrame.
    &#34;&#34;&#34;
    columns = [&#39;protocol_id&#39;, &#34;elem_id&#34;, &#34;pattern&#34;, &#34;segmentation&#34;, &#34;who&#34;, &#34;id&#34;]
    data = []
    protocol_id = root.attrib[&#34;id&#34;]
    metadata = infer_metadata(protocol_id)
    pattern_rows = list(pattern_db.iterrows())
    
    mp_db = mp_db[mp_db[&#34;chamber&#34;] == metadata[&#34;chamber&#34;]]
    names = mp_db[&#34;name&#34;]
    ids = mp_db[&#34;id&#34;]
    names_ids = list(zip(names,ids))
    
    expressions = dict()
    manual = dict()
    for _, row in pattern_db.iterrows():
        if row[&#34;type&#34;] == &#34;regex&#34;:
            pattern = row[&#39;pattern&#39;]
            exp = re.compile(pattern)
            #Calculate digest for distringuishing patterns without ugly characters
            pattern_digest = hashlib.md5(pattern.encode(&#34;utf-8&#34;)).hexdigest()[:16]
            expressions[pattern_digest] = exp
        elif row[&#34;type&#34;] == &#34;manual&#34;:
            manual[row[&#34;pattern&#34;]] = row[&#34;segmentation&#34;]
    
    prot_speeches = dict()
    for content_block in root:
        cb_id = content_block.attrib[&#34;id&#34;]
        content_txt = &#39;\n&#39;.join(content_block.itertext())
        if not _is_metadata_block(content_txt):
            for textblock in content_block:
                tb_id = textblock.attrib[&#34;id&#34;]
                paragraph = textblock.text

                # Do not do segmentation if paragraph is empty
                if type(paragraph) != str:
                    continue

                for pattern, segmentation in manual.items():
                    if pattern in paragraph:
                        person = _detect_mp(matched_txt, names_ids)
                        #person = _detect_mp(matched_txt, names_ids)
                        d = {&#34;protocol_id&#34;: protocol_id,
                            &#34;pattern&#34;: &#34;manual&#34;,
                            &#34;segmentation&#34;: segmentation,
                            &#34;elem_id&#34;: tb_id,
                            }
                        continue

                # Detect speaker introductions
                segmentation = None
                for pattern_digest, exp in expressions.items():
                    for m in exp.finditer(paragraph):
                        matched_txt = m.group()
                        person = _detect_mp(matched_txt, names_ids)
                        segmentation = &#34;speech_start&#34;
                        d = {
                        &#34;protocol_id&#34;: protocol_id,
                        &#34;pattern&#34;: pattern_digest,
                        &#34;who&#34;: person,
                        &#34;segmentation&#34;: segmentation,
                        &#34;elem_id&#34;: tb_id,
                        }

                        data.append(d)

                        break

                # Do not do further segmentation if speech is detected
                if segmentation is not None:
                    continue

                # Use ML model to classify paragraph
                if classifier is not None:
                    preds = classify_paragraph(paragraph, classifier)
                    if np.argmax(preds) == 1:
                        segmentation = &#34;note&#34;
                        d = {
                        &#34;protocol_id&#34;: protocol_id,
                        &#34;segmentation&#34;: segmentation,
                        &#34;elem_id&#34;: tb_id,
                        }

                        data.append(d)
        else:
            d = {&#34;protocol_id&#34;: protocol_id, &#34;pattern&#34;: None, &#34;who&#34;: None, &#34;segmentation&#34;: &#34;metadata&#34;}
            d[&#34;elem_id&#34;] = cb_id
            data.append(d)

    return pd.DataFrame(data, columns=columns)

def apply_instances(protocol, instance_db):
    protocol_id = protocol.attrib[&#34;id&#34;]
    
    applicable_instances = instance_db[instance_db[&#34;protocol_id&#34;] == protocol_id]
    applicable_instances = applicable_instances.drop_duplicates(subset=[&#39;elem_id&#39;])

    for _, row in applicable_instances.iterrows():
        elem_id = row[&#34;elem_id&#34;]
        for target in protocol.xpath(&#34;//*[@id=&#39;&#34; + elem_id + &#34;&#39;]&#34;):
            target.attrib[&#34;segmentation&#34;] = row[&#34;segmentation&#34;]
            if type(row[&#34;who&#34;]) == str:
                target.attrib[&#34;who&#34;] = row[&#34;who&#34;]

            if type(row[&#34;id&#34;]) == str:
                target.attrib[&#34;id&#34;] = row[&#34;id&#34;]

    return protocol
    
def find_instances(protocol_id, archive, pattern_db, mp_db, classifier=None):
    page_content_blocks = get_blocks(protocol_id, archive)
    instance_db = find_instances_xml(page_content_blocks, pattern_db, mp_db, classifier=classifier)
    
    instance_db[&#34;protocol_id&#34;] = protocol_id
    return instance_db
    
def segmentation_workflow(file_db, archive, pattern_db, mp_db, ml=True):
    classifier = None
    if ml:
        import tensorflow as tf
        import fasttext.util

        model = tf.keras.models.load_model(&#34;segment-classifier&#34;)
        ft = fasttext.load_model(&#39;cc.sv.300.bin&#39;)

        classifier = dict(
            model=model,
            ft=ft,
            dim=ft.get_word_vector(&#34;hej&#34;).shape[0]
        )

    instance_dbs = []
    for corpus_year, package_ids, _ in year_iterator(file_db):
        print(&#34;Segmenting year:&#34;, corpus_year)
        
        year_patterns = filter_db(pattern_db, year=corpus_year)
        year_mps = filter_db(mp_db, year=corpus_year)
        
        for protocol_id in progressbar.progressbar(package_ids):
            protocol_patterns = filter_db(pattern_db, protocol_id=protocol_id)
            protocol_patterns = pd.concat([protocol_patterns, year_patterns])
            instance_db = find_instances(protocol_id, archive, protocol_patterns, year_mps, classifier=classifier)
            instance_dbs.append(instance_db)
    
    return pd.concat(instance_dbs)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="riksdagen_corpus.segmentation.apply_instances"><code class="name flex">
<span>def <span class="ident">apply_instances</span></span>(<span>protocol, instance_db)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_instances(protocol, instance_db):
    protocol_id = protocol.attrib[&#34;id&#34;]
    
    applicable_instances = instance_db[instance_db[&#34;protocol_id&#34;] == protocol_id]
    applicable_instances = applicable_instances.drop_duplicates(subset=[&#39;elem_id&#39;])

    for _, row in applicable_instances.iterrows():
        elem_id = row[&#34;elem_id&#34;]
        for target in protocol.xpath(&#34;//*[@id=&#39;&#34; + elem_id + &#34;&#39;]&#34;):
            target.attrib[&#34;segmentation&#34;] = row[&#34;segmentation&#34;]
            if type(row[&#34;who&#34;]) == str:
                target.attrib[&#34;who&#34;] = row[&#34;who&#34;]

            if type(row[&#34;id&#34;]) == str:
                target.attrib[&#34;id&#34;] = row[&#34;id&#34;]

    return protocol</code></pre>
</details>
</dd>
<dt id="riksdagen_corpus.segmentation.classify_paragraph"><code class="name flex">
<span>def <span class="ident">classify_paragraph</span></span>(<span>paragraph, classifier, prior=array([-0.22314355, -1.60943791]))</span>
</code></dt>
<dd>
<div class="desc"><p>Classify paragraph into speeches / descriptions with provided classifier</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def classify_paragraph(paragraph, classifier, prior=np.log([0.8, 0.2])):
    &#34;&#34;&#34;
    Classify paragraph into speeches / descriptions with provided classifier

    &#34;&#34;&#34;
    words = paragraph.split()
    V = len(words)
    if V == 0:
        return prior

    x = np.zeros((V, classifier[&#34;dim&#34;]))

    ft = classifier[&#34;ft&#34;]
    for ix, word in enumerate(words):
        vec = ft.get_word_vector(word)
        x[ix] = vec

    pred = classifier[&#34;model&#34;].predict(x, batch_size=V)
    return np.sum(pred, axis=0) + prior</code></pre>
</details>
</dd>
<dt id="riksdagen_corpus.segmentation.find_instances"><code class="name flex">
<span>def <span class="ident">find_instances</span></span>(<span>protocol_id, archive, pattern_db, mp_db, classifier=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_instances(protocol_id, archive, pattern_db, mp_db, classifier=None):
    page_content_blocks = get_blocks(protocol_id, archive)
    instance_db = find_instances_xml(page_content_blocks, pattern_db, mp_db, classifier=classifier)
    
    instance_db[&#34;protocol_id&#34;] = protocol_id
    return instance_db</code></pre>
</details>
</dd>
<dt id="riksdagen_corpus.segmentation.find_instances_xml"><code class="name flex">
<span>def <span class="ident">find_instances_xml</span></span>(<span>root, pattern_db, mp_db, classifier)</span>
</code></dt>
<dd>
<div class="desc"><p>Find instances of segment start and end patterns in a txt file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>root</code></strong></dt>
<dd>root of an lxml tree to be pattern matched.</dd>
<dt><strong><code>pattern_db</code></strong></dt>
<dd>Patterns to be matched as a Pandas DataFrame.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_instances_xml(root, pattern_db, mp_db, classifier):
    &#34;&#34;&#34;
    Find instances of segment start and end patterns in a txt file.

    Args:
        root: root of an lxml tree to be pattern matched.
        pattern_db: Patterns to be matched as a Pandas DataFrame.
    &#34;&#34;&#34;
    columns = [&#39;protocol_id&#39;, &#34;elem_id&#34;, &#34;pattern&#34;, &#34;segmentation&#34;, &#34;who&#34;, &#34;id&#34;]
    data = []
    protocol_id = root.attrib[&#34;id&#34;]
    metadata = infer_metadata(protocol_id)
    pattern_rows = list(pattern_db.iterrows())
    
    mp_db = mp_db[mp_db[&#34;chamber&#34;] == metadata[&#34;chamber&#34;]]
    names = mp_db[&#34;name&#34;]
    ids = mp_db[&#34;id&#34;]
    names_ids = list(zip(names,ids))
    
    expressions = dict()
    manual = dict()
    for _, row in pattern_db.iterrows():
        if row[&#34;type&#34;] == &#34;regex&#34;:
            pattern = row[&#39;pattern&#39;]
            exp = re.compile(pattern)
            #Calculate digest for distringuishing patterns without ugly characters
            pattern_digest = hashlib.md5(pattern.encode(&#34;utf-8&#34;)).hexdigest()[:16]
            expressions[pattern_digest] = exp
        elif row[&#34;type&#34;] == &#34;manual&#34;:
            manual[row[&#34;pattern&#34;]] = row[&#34;segmentation&#34;]
    
    prot_speeches = dict()
    for content_block in root:
        cb_id = content_block.attrib[&#34;id&#34;]
        content_txt = &#39;\n&#39;.join(content_block.itertext())
        if not _is_metadata_block(content_txt):
            for textblock in content_block:
                tb_id = textblock.attrib[&#34;id&#34;]
                paragraph = textblock.text

                # Do not do segmentation if paragraph is empty
                if type(paragraph) != str:
                    continue

                for pattern, segmentation in manual.items():
                    if pattern in paragraph:
                        person = _detect_mp(matched_txt, names_ids)
                        #person = _detect_mp(matched_txt, names_ids)
                        d = {&#34;protocol_id&#34;: protocol_id,
                            &#34;pattern&#34;: &#34;manual&#34;,
                            &#34;segmentation&#34;: segmentation,
                            &#34;elem_id&#34;: tb_id,
                            }
                        continue

                # Detect speaker introductions
                segmentation = None
                for pattern_digest, exp in expressions.items():
                    for m in exp.finditer(paragraph):
                        matched_txt = m.group()
                        person = _detect_mp(matched_txt, names_ids)
                        segmentation = &#34;speech_start&#34;
                        d = {
                        &#34;protocol_id&#34;: protocol_id,
                        &#34;pattern&#34;: pattern_digest,
                        &#34;who&#34;: person,
                        &#34;segmentation&#34;: segmentation,
                        &#34;elem_id&#34;: tb_id,
                        }

                        data.append(d)

                        break

                # Do not do further segmentation if speech is detected
                if segmentation is not None:
                    continue

                # Use ML model to classify paragraph
                if classifier is not None:
                    preds = classify_paragraph(paragraph, classifier)
                    if np.argmax(preds) == 1:
                        segmentation = &#34;note&#34;
                        d = {
                        &#34;protocol_id&#34;: protocol_id,
                        &#34;segmentation&#34;: segmentation,
                        &#34;elem_id&#34;: tb_id,
                        }

                        data.append(d)
        else:
            d = {&#34;protocol_id&#34;: protocol_id, &#34;pattern&#34;: None, &#34;who&#34;: None, &#34;segmentation&#34;: &#34;metadata&#34;}
            d[&#34;elem_id&#34;] = cb_id
            data.append(d)

    return pd.DataFrame(data, columns=columns)</code></pre>
</details>
</dd>
<dt id="riksdagen_corpus.segmentation.segmentation_workflow"><code class="name flex">
<span>def <span class="ident">segmentation_workflow</span></span>(<span>file_db, archive, pattern_db, mp_db, ml=True)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def segmentation_workflow(file_db, archive, pattern_db, mp_db, ml=True):
    classifier = None
    if ml:
        import tensorflow as tf
        import fasttext.util

        model = tf.keras.models.load_model(&#34;segment-classifier&#34;)
        ft = fasttext.load_model(&#39;cc.sv.300.bin&#39;)

        classifier = dict(
            model=model,
            ft=ft,
            dim=ft.get_word_vector(&#34;hej&#34;).shape[0]
        )

    instance_dbs = []
    for corpus_year, package_ids, _ in year_iterator(file_db):
        print(&#34;Segmenting year:&#34;, corpus_year)
        
        year_patterns = filter_db(pattern_db, year=corpus_year)
        year_mps = filter_db(mp_db, year=corpus_year)
        
        for protocol_id in progressbar.progressbar(package_ids):
            protocol_patterns = filter_db(pattern_db, protocol_id=protocol_id)
            protocol_patterns = pd.concat([protocol_patterns, year_patterns])
            instance_db = find_instances(protocol_id, archive, protocol_patterns, year_mps, classifier=classifier)
            instance_dbs.append(instance_db)
    
    return pd.concat(instance_dbs)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="riksdagen_corpus" href="index.html">riksdagen_corpus</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="riksdagen_corpus.segmentation.apply_instances" href="#riksdagen_corpus.segmentation.apply_instances">apply_instances</a></code></li>
<li><code><a title="riksdagen_corpus.segmentation.classify_paragraph" href="#riksdagen_corpus.segmentation.classify_paragraph">classify_paragraph</a></code></li>
<li><code><a title="riksdagen_corpus.segmentation.find_instances" href="#riksdagen_corpus.segmentation.find_instances">find_instances</a></code></li>
<li><code><a title="riksdagen_corpus.segmentation.find_instances_xml" href="#riksdagen_corpus.segmentation.find_instances_xml">find_instances_xml</a></code></li>
<li><code><a title="riksdagen_corpus.segmentation.segmentation_workflow" href="#riksdagen_corpus.segmentation.segmentation_workflow">segmentation_workflow</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>